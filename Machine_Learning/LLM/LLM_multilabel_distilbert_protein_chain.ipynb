{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>LLM - Using DistilBert for Protein Function Classification</h1>\n",
        "<h2> By Edwin Tembo - 2023</h2>"
      ],
      "metadata": {
        "id": "OgdCopXcb4se"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt1MyxKIzyMF",
        "outputId": "6c90df67-e862-417c-8821-2cdd6deeebe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgnBQtf9vXiG",
        "outputId": "293b017a-9689-49e3-dc22-ac6df39ae30d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan  9 02:57:28 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0              25W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTkCDy7NPuOx",
        "outputId": "930ddbcb-2fbb-4c98-89ad-bb67a1d518d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHxRRzqpBf76"
      },
      "outputs": [],
      "source": [
        "# Importing stock ml libraries\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn import metrics\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "import logging\n",
        "import ast\n",
        "import datetime\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "torch.cuda.empty_cache()\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.DEBUG)\n",
        "logger.addHandler(logging.StreamHandler(sys.stdout))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxZOyiSMxwPl"
      },
      "outputs": [],
      "source": [
        "writer = SummaryWriter(log_dir='/content/drive/MyDrive/protein/CAFA_TORCH_RUNS')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7N-SkxWC7zT"
      },
      "outputs": [],
      "source": [
        "# # Setting up the device for GPU usage\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tr6XeiZW3YbT"
      },
      "outputs": [],
      "source": [
        "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
        "    acc_list = []\n",
        "    for i in range(y_true.shape[0]):\n",
        "        set_true = set( np.where(y_true[i])[0] )\n",
        "        set_pred = set( np.where(y_pred[i])[0] )\n",
        "        tmp_a = None\n",
        "        if len(set_true) == 0 and len(set_pred) == 0:\n",
        "            tmp_a = 1\n",
        "        else:\n",
        "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
        "                    float( len(set_true.union(set_pred)) )\n",
        "        acc_list.append(tmp_a)\n",
        "    return np.mean(acc_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oXQo4odYvDvM",
        "outputId": "b6a60e3e-b3b5-49f1-d65a-8e69a80bf27d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  M N S V T V S H A P Y T I T Y H D D W E P V M ...   \n",
              "1  M T E Y R N F L L L F I T S L S V I Y P C T G ...   \n",
              "2  M R L S S S P P R G P Q Q L S S F G S V D W L ...   \n",
              "3  M G G E A G A D G P R G R V K S L G L V F E D ...   \n",
              "4  M V E T N S P P A G Y T L K R S P S D L G E Q ...   \n",
              "\n",
              "                                              labels  \n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "1  [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, ...  \n",
              "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-c84e9081-389e-4986-a4d2-9b47dd93c6a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M N S V T V S H A P Y T I T Y H D D W E P V M ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M T E Y R N F L L L F I T S L S V I Y P C T G ...</td>\n",
              "      <td>[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M R L S S S P P R G P Q Q L S S F G S V D W L ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M G G E A G A D G P R G R V K S L G L V F E D ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M V E T N S P P A G Y T L K R S P S D L G E Q ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c84e9081-389e-4986-a4d2-9b47dd93c6a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-d74e4350-aee4-4496-8de5-2715e16f8219\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d74e4350-aee4-4496-8de5-2715e16f8219')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-d74e4350-aee4-4496-8de5-2715e16f8219 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c84e9081-389e-4986-a4d2-9b47dd93c6a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c84e9081-389e-4986-a4d2-9b47dd93c6a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/protein/CAFA_SEQ_DATA/train_data.csv')\n",
        "data.drop(['id'], inplace=True, axis=1)\n",
        "data.rename(columns = {\"sequence\": \"text\"}, inplace=True)\n",
        "new_df = data\n",
        "new_df[\"labels\"] = new_df.labels.apply(ast.literal_eval)\n",
        "new_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpF4ZAaxC_OJ",
        "outputId": "52a0bf20-bf8c-46a6-b38e-2da0d40cc2e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'DistilBertTokenizer'.\n"
          ]
        }
      ],
      "source": [
        "# Sections of config\n",
        "\n",
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 1024\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 4\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-05\n",
        "PRE_TRAINED_MODEL ='Rostlab/prot_bert'\n",
        "MODEL_VOCAB = '/content/drive/MyDrive/protein/CAFA_TORCH_MODELS/vocab_distilbert_protBert.bin'\n",
        "\n",
        "NUM_LABELS        = 500\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_VOCAB, truncation=True, do_lower_case=True)\n",
        "SEED = 567"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fC7zA4nYDGX3"
      },
      "outputs": [],
      "source": [
        "class MultiLabelDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.text\n",
        "        self.targets = self.data.labels\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        ##text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }\n",
        "\n",
        "class InferenceDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.text\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOZWsLfGDOBG",
        "outputId": "ba2df070-e489-43e7-e7a2-66ac145790fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (142246, 2)\n",
            "TRAIN Dataset: (113797, 2)\n",
            "TEST Dataset: (28449, 2)\n"
          ]
        }
      ],
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "\n",
        "train_size = 0.8\n",
        "train_data=new_df.sample(frac=train_size,random_state=SEED)\n",
        "test_data=new_df.drop(train_data.index).reset_index(drop=True)\n",
        "train_data = train_data.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(new_df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
        "\n",
        "training_set = MultiLabelDataset(train_data, tokenizer, MAX_LEN)\n",
        "testing_set = MultiLabelDataset(test_data, tokenizer, MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StbPlIyKDP9E"
      },
      "outputs": [],
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830,
          "referenced_widgets": [
            "3494243b3a034b139eb6f5bd648368bd",
            "f5e2eaa539bc483f9717daaee1db88c6",
            "1161b5d9b17448ffa9aff9164ae69943",
            "140bcb2a5b77454dbf0bf2fecb770c2e",
            "af8b40f775694feebd1cf6b4412fa8b0",
            "e3eea9b5553d4280a7b6245a2c18d016",
            "16bb2a21de024534a727bb2b84516d9a",
            "1afa3f7834594474920c9a59f3ccba37",
            "b3615ea8e2304a3ab684d1ba4346e1f5",
            "146b314d591246d38358e1d9b64336b7",
            "0366f9f18b3c44e982a0f942fbc73e32",
            "f218ce8509cd47f9b6ee8327df924192",
            "ea04a52557d74567ae0650e332f44e8c",
            "5a429c5adb30450ea022595c4e46e2ca",
            "d0465cd2627646f19c3e8f4fb18d8743",
            "c2b52c68d11e40f1a73e89757e669db5",
            "144c17728f74475083aca93270804193",
            "d4a654d274fb4766b53595d07acd6a14",
            "9ca6e8a40d8840859e71a17f623f7000",
            "322a8704cfc9461bbfb3c386391bd44d",
            "eeb2c08a85924c63917ef21bd6fb07bb",
            "93a7309b12b54eefacf5cf36e33daaec"
          ]
        },
        "id": "FeftvDhjDSPp",
        "outputId": "e0a8be52-8a8b-4668-cb84-cd26084ef626"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/361 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3494243b3a034b139eb6f5bd648368bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.68G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f218ce8509cd47f9b6ee8327df924192"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing DistilBertModel: ['bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.13.attention.self.query.weight', 'bert.encoder.layer.18.attention.output.LayerNorm.weight', 'bert.encoder.layer.12.attention.output.dense.bias', 'bert.encoder.layer.19.attention.self.value.bias', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.20.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.29.attention.self.query.weight', 'bert.encoder.layer.29.intermediate.dense.bias', 'bert.encoder.layer.25.attention.output.dense.bias', 'bert.encoder.layer.20.attention.self.query.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.12.output.dense.bias', 'bert.encoder.layer.25.intermediate.dense.weight', 'bert.encoder.layer.29.attention.self.key.bias', 'bert.encoder.layer.18.output.LayerNorm.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.15.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.16.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.27.output.dense.bias', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.29.attention.self.query.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.22.attention.self.value.bias', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.19.output.dense.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.14.attention.self.query.weight', 'bert.encoder.layer.12.attention.self.query.bias', 'bert.encoder.layer.20.intermediate.dense.bias', 'bert.encoder.layer.21.attention.output.dense.weight', 'bert.encoder.layer.29.attention.output.LayerNorm.bias', 'bert.encoder.layer.14.attention.output.dense.bias', 'bert.encoder.layer.26.output.LayerNorm.weight', 'bert.encoder.layer.20.attention.output.LayerNorm.bias', 'bert.encoder.layer.12.output.dense.weight', 'bert.encoder.layer.15.output.dense.bias', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.24.attention.output.LayerNorm.bias', 'bert.encoder.layer.21.attention.self.query.bias', 'bert.encoder.layer.24.output.LayerNorm.bias', 'bert.encoder.layer.26.attention.self.value.weight', 'bert.encoder.layer.23.attention.self.query.bias', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.24.attention.self.value.weight', 'bert.encoder.layer.19.intermediate.dense.bias', 'bert.encoder.layer.18.output.LayerNorm.bias', 'bert.encoder.layer.13.intermediate.dense.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.16.attention.self.value.weight', 'bert.encoder.layer.21.attention.output.LayerNorm.bias', 'bert.encoder.layer.19.output.LayerNorm.weight', 'bert.encoder.layer.27.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.27.attention.output.dense.bias', 'bert.encoder.layer.27.attention.output.LayerNorm.bias', 'bert.encoder.layer.24.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.26.attention.self.query.bias', 'bert.encoder.layer.26.attention.self.value.bias', 'bert.encoder.layer.19.attention.self.query.weight', 'bert.encoder.layer.25.output.dense.weight', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.24.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.21.attention.output.dense.bias', 'bert.encoder.layer.20.attention.self.key.bias', 'bert.encoder.layer.19.attention.output.LayerNorm.bias', 'bert.encoder.layer.25.output.LayerNorm.weight', 'bert.encoder.layer.13.output.LayerNorm.weight', 'bert.encoder.layer.22.output.LayerNorm.bias', 'bert.encoder.layer.25.attention.self.key.bias', 'bert.encoder.layer.29.attention.self.value.weight', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.13.output.dense.bias', 'bert.encoder.layer.14.output.LayerNorm.weight', 'bert.encoder.layer.15.output.dense.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.14.intermediate.dense.bias', 'bert.encoder.layer.27.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.22.attention.self.value.weight', 'bert.encoder.layer.25.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.25.attention.output.LayerNorm.weight', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.23.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.26.attention.output.LayerNorm.bias', 'bert.encoder.layer.16.attention.self.query.weight', 'bert.encoder.layer.14.attention.output.dense.weight', 'bert.encoder.layer.22.attention.output.dense.weight', 'bert.encoder.layer.19.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.24.output.LayerNorm.weight', 'bert.encoder.layer.29.output.dense.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.12.intermediate.dense.weight', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.17.attention.output.dense.bias', 'bert.encoder.layer.19.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.21.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.17.attention.self.value.weight', 'cls.predictions.bias', 'bert.encoder.layer.13.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.22.intermediate.dense.weight', 'bert.encoder.layer.14.attention.self.key.weight', 'bert.encoder.layer.24.attention.output.dense.weight', 'bert.encoder.layer.24.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.19.attention.self.query.bias', 'bert.encoder.layer.20.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.14.attention.self.query.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.15.intermediate.dense.bias', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.24.attention.output.LayerNorm.weight', 'bert.encoder.layer.25.output.LayerNorm.bias', 'bert.encoder.layer.14.output.LayerNorm.bias', 'bert.encoder.layer.28.intermediate.dense.weight', 'bert.encoder.layer.25.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.17.attention.output.LayerNorm.bias', 'bert.encoder.layer.23.attention.output.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.21.attention.self.query.weight', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.17.intermediate.dense.bias', 'bert.encoder.layer.17.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.20.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.21.attention.self.key.bias', 'bert.encoder.layer.28.attention.self.value.weight', 'bert.encoder.layer.13.output.dense.weight', 'bert.encoder.layer.28.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.15.attention.output.dense.weight', 'bert.encoder.layer.27.output.LayerNorm.bias', 'cls.predictions.decoder.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.18.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.29.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.21.attention.self.key.weight', 'bert.encoder.layer.20.output.LayerNorm.weight', 'bert.encoder.layer.28.output.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.17.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.27.attention.self.value.bias', 'bert.encoder.layer.29.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.12.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.28.attention.self.query.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.17.attention.output.dense.weight', 'bert.encoder.layer.20.attention.output.dense.bias', 'bert.encoder.layer.28.attention.output.LayerNorm.bias', 'bert.encoder.layer.14.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.18.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.16.output.LayerNorm.bias', 'bert.encoder.layer.24.attention.self.value.bias', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.27.output.dense.weight', 'bert.encoder.layer.29.attention.self.key.weight', 'bert.encoder.layer.27.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'cls.predictions.decoder.weight', 'bert.encoder.layer.29.output.dense.weight', 'bert.encoder.layer.21.attention.output.LayerNorm.weight', 'bert.encoder.layer.20.output.dense.bias', 'bert.encoder.layer.29.attention.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.24.output.dense.bias', 'bert.pooler.dense.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.21.output.LayerNorm.weight', 'bert.encoder.layer.23.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.27.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.21.attention.self.value.bias', 'bert.encoder.layer.18.intermediate.dense.weight', 'bert.encoder.layer.12.attention.self.query.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.19.attention.self.key.weight', 'bert.encoder.layer.23.output.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.26.attention.output.dense.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.23.attention.self.key.bias', 'bert.encoder.layer.13.attention.self.query.bias', 'bert.encoder.layer.14.output.dense.bias', 'bert.encoder.layer.24.output.dense.weight', 'bert.encoder.layer.19.output.dense.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.14.intermediate.dense.weight', 'bert.encoder.layer.18.attention.self.key.bias', 'bert.encoder.layer.16.output.dense.bias', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.19.attention.output.dense.bias', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.25.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.26.attention.output.dense.weight', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.embeddings.position_embeddings.weight', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.17.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.17.attention.self.query.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.23.attention.self.value.weight', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.16.intermediate.dense.bias', 'bert.encoder.layer.26.output.dense.bias', 'bert.encoder.layer.12.attention.output.LayerNorm.bias', 'bert.encoder.layer.13.output.LayerNorm.bias', 'bert.encoder.layer.24.intermediate.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.14.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.29.output.LayerNorm.weight', 'bert.encoder.layer.13.attention.self.value.bias', 'bert.encoder.layer.22.attention.output.dense.bias', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.22.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.28.attention.output.dense.bias', 'bert.encoder.layer.17.attention.self.query.bias', 'bert.encoder.layer.28.attention.self.value.bias', 'bert.encoder.layer.13.attention.output.LayerNorm.weight', 'bert.encoder.layer.12.attention.output.dense.weight', 'bert.encoder.layer.23.attention.output.dense.weight', 'bert.encoder.layer.16.output.LayerNorm.weight', 'bert.encoder.layer.16.attention.self.key.bias', 'bert.encoder.layer.20.intermediate.dense.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.20.attention.self.value.bias', 'bert.encoder.layer.13.attention.output.dense.weight', 'bert.encoder.layer.15.attention.self.key.weight', 'bert.encoder.layer.16.attention.self.value.bias', 'bert.encoder.layer.17.output.dense.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.27.attention.self.key.bias', 'bert.encoder.layer.20.output.dense.weight', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.26.attention.self.key.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.17.intermediate.dense.weight', 'bert.encoder.layer.18.attention.output.dense.weight', 'bert.encoder.layer.27.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.19.attention.self.key.bias', 'bert.encoder.layer.28.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.23.intermediate.dense.bias', 'cls.seq_relationship.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.18.output.dense.weight', 'bert.encoder.layer.23.output.LayerNorm.weight', 'bert.encoder.layer.19.intermediate.dense.weight', 'bert.encoder.layer.14.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.21.output.dense.bias', 'bert.encoder.layer.12.output.LayerNorm.bias', 'bert.encoder.layer.29.attention.output.dense.weight', 'bert.encoder.layer.22.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.18.attention.self.query.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.23.attention.self.key.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.15.attention.output.LayerNorm.bias', 'bert.encoder.layer.17.attention.self.value.bias', 'bert.encoder.layer.28.attention.self.key.weight', 'bert.encoder.layer.23.attention.self.value.bias', 'bert.encoder.layer.16.attention.output.LayerNorm.weight', 'bert.encoder.layer.25.intermediate.dense.bias', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.25.attention.self.value.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.16.attention.self.query.bias', 'bert.encoder.layer.12.attention.self.key.weight', 'bert.encoder.layer.12.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.27.intermediate.dense.weight', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.26.output.dense.weight', 'bert.encoder.layer.12.intermediate.dense.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.26.attention.self.key.bias', 'bert.encoder.layer.20.output.LayerNorm.bias', 'bert.encoder.layer.23.output.dense.weight', 'bert.encoder.layer.15.attention.self.query.bias', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.25.output.dense.bias', 'bert.encoder.layer.13.attention.self.key.bias', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.14.output.dense.weight', 'bert.encoder.layer.17.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.13.attention.self.key.weight', 'bert.encoder.layer.28.output.dense.bias', 'bert.encoder.layer.28.intermediate.dense.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.16.attention.output.dense.bias', 'bert.encoder.layer.16.attention.output.dense.weight', 'bert.encoder.layer.15.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.23.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.encoder.layer.18.attention.self.value.weight', 'bert.encoder.layer.25.attention.self.query.bias', 'bert.encoder.layer.18.attention.self.query.bias', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.22.attention.self.query.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.12.attention.output.LayerNorm.weight', 'bert.encoder.layer.13.attention.self.value.weight', 'bert.encoder.layer.22.attention.self.key.bias', 'bert.encoder.layer.24.attention.self.query.bias', 'bert.encoder.layer.16.attention.self.key.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.15.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.28.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.21.intermediate.dense.weight', 'bert.encoder.layer.14.attention.output.LayerNorm.weight', 'bert.encoder.layer.27.attention.self.query.bias', 'bert.encoder.layer.29.attention.self.value.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.15.attention.self.value.bias', 'bert.encoder.layer.29.intermediate.dense.weight', 'bert.encoder.layer.22.output.dense.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.20.attention.self.key.weight', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.21.intermediate.dense.bias', 'bert.encoder.layer.15.attention.self.query.weight', 'bert.encoder.layer.15.attention.output.LayerNorm.weight', 'bert.encoder.layer.26.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.23.intermediate.dense.weight', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.13.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.15.output.LayerNorm.bias', 'bert.encoder.layer.28.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.22.attention.output.LayerNorm.weight', 'bert.encoder.layer.26.attention.self.query.weight', 'bert.encoder.layer.19.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.18.output.dense.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.12.attention.self.value.bias', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.22.attention.self.key.weight', 'bert.encoder.layer.26.intermediate.dense.weight', 'bert.encoder.layer.14.attention.self.value.weight', 'bert.encoder.layer.20.attention.output.LayerNorm.weight', 'bert.encoder.layer.27.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.12.attention.self.value.weight', 'cls.seq_relationship.weight', 'bert.encoder.layer.21.output.LayerNorm.bias', 'bert.encoder.layer.18.attention.self.key.weight', 'bert.encoder.layer.26.output.LayerNorm.bias', 'bert.encoder.layer.24.attention.self.key.bias', 'bert.encoder.layer.22.output.dense.weight', 'bert.encoder.layer.25.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.27.attention.self.key.weight', 'bert.encoder.layer.17.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.17.output.dense.bias', 'bert.encoder.layer.13.attention.output.dense.bias', 'bert.encoder.layer.21.output.dense.weight', 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.15.intermediate.dense.weight', 'bert.encoder.layer.16.output.dense.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.16.intermediate.dense.weight', 'bert.encoder.layer.18.intermediate.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.28.attention.self.key.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.25.attention.output.dense.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.15.attention.self.value.weight', 'bert.encoder.layer.24.attention.self.key.weight', 'bert.encoder.layer.18.attention.self.value.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.22.attention.self.query.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.26.intermediate.dense.bias', 'bert.pooler.dense.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.28.attention.self.query.weight', 'bert.encoder.layer.19.attention.output.dense.weight', 'bert.encoder.layer.23.attention.self.query.weight', 'bert.encoder.layer.22.intermediate.dense.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertModel were not initialized from the model checkpoint at Rostlab/prot_bert and are newly initialized: ['transformer.layer.17.attention.out_lin.weight', 'transformer.layer.27.attention.v_lin.weight', 'transformer.layer.9.output_layer_norm.bias', 'transformer.layer.6.output_layer_norm.weight', 'transformer.layer.22.ffn.lin1.bias', 'transformer.layer.27.output_layer_norm.weight', 'transformer.layer.27.sa_layer_norm.bias', 'transformer.layer.4.ffn.lin2.weight', 'transformer.layer.22.attention.q_lin.weight', 'transformer.layer.0.ffn.lin2.bias', 'transformer.layer.15.ffn.lin1.bias', 'transformer.layer.4.attention.q_lin.weight', 'transformer.layer.24.attention.k_lin.weight', 'transformer.layer.19.sa_layer_norm.weight', 'transformer.layer.18.output_layer_norm.weight', 'transformer.layer.2.ffn.lin1.bias', 'transformer.layer.9.attention.out_lin.bias', 'transformer.layer.14.attention.k_lin.weight', 'transformer.layer.15.attention.q_lin.bias', 'transformer.layer.24.attention.out_lin.bias', 'transformer.layer.26.attention.out_lin.bias', 'transformer.layer.27.attention.q_lin.weight', 'transformer.layer.10.ffn.lin2.bias', 'transformer.layer.7.ffn.lin1.bias', 'transformer.layer.28.sa_layer_norm.bias', 'transformer.layer.10.attention.out_lin.bias', 'transformer.layer.6.attention.out_lin.weight', 'transformer.layer.10.output_layer_norm.weight', 'transformer.layer.15.attention.v_lin.bias', 'transformer.layer.13.attention.k_lin.weight', 'transformer.layer.6.attention.v_lin.bias', 'transformer.layer.0.attention.k_lin.bias', 'transformer.layer.25.attention.out_lin.bias', 'transformer.layer.21.attention.v_lin.bias', 'transformer.layer.29.ffn.lin1.bias', 'transformer.layer.0.attention.out_lin.weight', 'transformer.layer.7.attention.k_lin.weight', 'transformer.layer.9.attention.q_lin.weight', 'transformer.layer.23.ffn.lin2.weight', 'transformer.layer.10.attention.q_lin.weight', 'transformer.layer.12.attention.q_lin.bias', 'transformer.layer.10.output_layer_norm.bias', 'transformer.layer.22.attention.k_lin.bias', 'transformer.layer.24.ffn.lin2.bias', 'transformer.layer.4.ffn.lin1.weight', 'transformer.layer.4.attention.k_lin.weight', 'transformer.layer.4.ffn.lin2.bias', 'transformer.layer.8.ffn.lin1.bias', 'transformer.layer.9.attention.out_lin.weight', 'transformer.layer.16.ffn.lin1.bias', 'transformer.layer.12.output_layer_norm.weight', 'transformer.layer.23.attention.out_lin.weight', 'transformer.layer.6.sa_layer_norm.bias', 'transformer.layer.13.attention.v_lin.bias', 'transformer.layer.29.output_layer_norm.bias', 'transformer.layer.26.output_layer_norm.weight', 'transformer.layer.3.sa_layer_norm.weight', 'transformer.layer.7.attention.out_lin.bias', 'transformer.layer.1.attention.k_lin.bias', 'transformer.layer.25.attention.v_lin.weight', 'transformer.layer.18.ffn.lin2.weight', 'transformer.layer.6.attention.v_lin.weight', 'transformer.layer.2.attention.k_lin.weight', 'transformer.layer.26.ffn.lin1.weight', 'transformer.layer.23.attention.q_lin.bias', 'transformer.layer.28.attention.out_lin.bias', 'transformer.layer.4.attention.out_lin.bias', 'transformer.layer.19.attention.q_lin.bias', 'transformer.layer.5.output_layer_norm.weight', 'transformer.layer.3.attention.out_lin.bias', 'transformer.layer.5.ffn.lin1.weight', 'transformer.layer.12.ffn.lin2.weight', 'transformer.layer.20.ffn.lin1.bias', 'transformer.layer.8.attention.v_lin.weight', 'transformer.layer.22.sa_layer_norm.bias', 'transformer.layer.3.attention.v_lin.weight', 'transformer.layer.0.ffn.lin1.bias', 'transformer.layer.24.ffn.lin1.bias', 'transformer.layer.15.ffn.lin2.weight', 'transformer.layer.12.ffn.lin2.bias', 'transformer.layer.12.attention.v_lin.bias', 'transformer.layer.1.ffn.lin2.weight', 'transformer.layer.17.attention.k_lin.weight', 'transformer.layer.12.attention.out_lin.bias', 'transformer.layer.9.attention.k_lin.bias', 'transformer.layer.2.attention.q_lin.weight', 'transformer.layer.0.ffn.lin2.weight', 'transformer.layer.16.attention.q_lin.bias', 'transformer.layer.23.attention.k_lin.weight', 'transformer.layer.5.attention.k_lin.bias', 'transformer.layer.15.sa_layer_norm.weight', 'transformer.layer.26.sa_layer_norm.bias', 'transformer.layer.14.attention.v_lin.weight', 'transformer.layer.9.sa_layer_norm.bias', 'transformer.layer.17.output_layer_norm.weight', 'transformer.layer.19.attention.k_lin.bias', 'transformer.layer.21.ffn.lin1.bias', 'transformer.layer.1.sa_layer_norm.bias', 'transformer.layer.21.attention.out_lin.weight', 'transformer.layer.3.ffn.lin1.weight', 'transformer.layer.26.attention.out_lin.weight', 'transformer.layer.26.sa_layer_norm.weight', 'transformer.layer.27.output_layer_norm.bias', 'transformer.layer.15.attention.k_lin.bias', 'transformer.layer.2.sa_layer_norm.bias', 'transformer.layer.21.attention.k_lin.bias', 'transformer.layer.19.output_layer_norm.bias', 'transformer.layer.9.output_layer_norm.weight', 'transformer.layer.25.attention.out_lin.weight', 'transformer.layer.5.sa_layer_norm.weight', 'transformer.layer.8.attention.k_lin.weight', 'transformer.layer.20.output_layer_norm.weight', 'transformer.layer.20.ffn.lin2.bias', 'transformer.layer.25.attention.q_lin.weight', 'transformer.layer.14.attention.q_lin.bias', 'transformer.layer.22.output_layer_norm.weight', 'transformer.layer.24.attention.q_lin.bias', 'transformer.layer.20.attention.v_lin.bias', 'transformer.layer.20.sa_layer_norm.bias', 'transformer.layer.17.attention.q_lin.weight', 'transformer.layer.19.attention.v_lin.weight', 'transformer.layer.25.output_layer_norm.weight', 'transformer.layer.14.attention.q_lin.weight', 'transformer.layer.14.attention.v_lin.bias', 'transformer.layer.17.sa_layer_norm.bias', 'transformer.layer.11.attention.v_lin.bias', 'transformer.layer.8.sa_layer_norm.weight', 'transformer.layer.15.attention.out_lin.bias', 'transformer.layer.10.ffn.lin1.bias', 'transformer.layer.29.attention.q_lin.weight', 'transformer.layer.1.ffn.lin2.bias', 'transformer.layer.7.output_layer_norm.weight', 'transformer.layer.19.attention.v_lin.bias', 'transformer.layer.17.output_layer_norm.bias', 'transformer.layer.8.ffn.lin2.weight', 'transformer.layer.10.attention.k_lin.bias', 'transformer.layer.10.sa_layer_norm.weight', 'transformer.layer.6.ffn.lin2.weight', 'transformer.layer.11.attention.k_lin.weight', 'transformer.layer.16.ffn.lin1.weight', 'transformer.layer.20.attention.k_lin.weight', 'transformer.layer.11.sa_layer_norm.weight', 'transformer.layer.21.attention.out_lin.bias', 'transformer.layer.0.attention.q_lin.weight', 'transformer.layer.27.attention.out_lin.bias', 'transformer.layer.5.attention.v_lin.bias', 'transformer.layer.12.attention.v_lin.weight', 'transformer.layer.8.output_layer_norm.weight', 'transformer.layer.27.attention.v_lin.bias', 'transformer.layer.2.attention.v_lin.bias', 'transformer.layer.14.ffn.lin2.weight', 'transformer.layer.7.attention.k_lin.bias', 'transformer.layer.20.attention.v_lin.weight', 'transformer.layer.25.attention.q_lin.bias', 'transformer.layer.23.ffn.lin1.weight', 'transformer.layer.7.sa_layer_norm.bias', 'transformer.layer.4.attention.q_lin.bias', 'transformer.layer.9.ffn.lin2.bias', 'transformer.layer.22.attention.out_lin.bias', 'transformer.layer.18.attention.out_lin.weight', 'transformer.layer.5.attention.out_lin.weight', 'transformer.layer.13.ffn.lin1.bias', 'transformer.layer.11.output_layer_norm.weight', 'transformer.layer.24.sa_layer_norm.weight', 'transformer.layer.27.attention.k_lin.bias', 'transformer.layer.21.attention.q_lin.weight', 'transformer.layer.22.attention.out_lin.weight', 'transformer.layer.10.attention.v_lin.bias', 'transformer.layer.20.output_layer_norm.bias', 'transformer.layer.1.attention.out_lin.bias', 'transformer.layer.14.ffn.lin2.bias', 'transformer.layer.0.attention.k_lin.weight', 'transformer.layer.1.output_layer_norm.bias', 'transformer.layer.28.attention.q_lin.bias', 'transformer.layer.5.attention.q_lin.bias', 'embeddings.LayerNorm.bias', 'transformer.layer.13.output_layer_norm.weight', 'transformer.layer.20.attention.q_lin.bias', 'transformer.layer.6.ffn.lin1.bias', 'transformer.layer.29.attention.k_lin.weight', 'transformer.layer.18.sa_layer_norm.weight', 'transformer.layer.5.ffn.lin1.bias', 'transformer.layer.12.attention.k_lin.bias', 'transformer.layer.16.attention.k_lin.weight', 'transformer.layer.28.sa_layer_norm.weight', 'transformer.layer.7.output_layer_norm.bias', 'transformer.layer.22.attention.v_lin.weight', 'transformer.layer.19.ffn.lin2.weight', 'transformer.layer.3.attention.q_lin.weight', 'transformer.layer.0.output_layer_norm.bias', 'transformer.layer.11.attention.out_lin.weight', 'transformer.layer.5.ffn.lin2.bias', 'transformer.layer.15.ffn.lin2.bias', 'transformer.layer.28.attention.q_lin.weight', 'transformer.layer.27.ffn.lin1.weight', 'transformer.layer.7.sa_layer_norm.weight', 'transformer.layer.21.ffn.lin2.weight', 'transformer.layer.6.attention.q_lin.bias', 'transformer.layer.16.attention.v_lin.weight', 'transformer.layer.14.attention.k_lin.bias', 'transformer.layer.19.output_layer_norm.weight', 'transformer.layer.16.sa_layer_norm.weight', 'transformer.layer.5.attention.k_lin.weight', 'transformer.layer.14.sa_layer_norm.weight', 'transformer.layer.20.attention.out_lin.weight', 'transformer.layer.8.ffn.lin1.weight', 'transformer.layer.28.ffn.lin1.weight', 'transformer.layer.18.attention.v_lin.bias', 'transformer.layer.28.attention.v_lin.weight', 'transformer.layer.13.attention.q_lin.bias', 'transformer.layer.6.attention.q_lin.weight', 'transformer.layer.24.attention.k_lin.bias', 'transformer.layer.14.ffn.lin1.bias', 'transformer.layer.25.ffn.lin2.weight', 'transformer.layer.3.attention.v_lin.bias', 'transformer.layer.19.ffn.lin2.bias', 'transformer.layer.23.output_layer_norm.bias', 'transformer.layer.29.ffn.lin1.weight', 'transformer.layer.1.attention.v_lin.bias', 'transformer.layer.23.attention.k_lin.bias', 'transformer.layer.2.output_layer_norm.bias', 'transformer.layer.2.attention.k_lin.bias', 'transformer.layer.27.sa_layer_norm.weight', 'transformer.layer.6.ffn.lin2.bias', 'transformer.layer.16.attention.k_lin.bias', 'transformer.layer.23.sa_layer_norm.weight', 'transformer.layer.26.ffn.lin2.weight', 'transformer.layer.16.output_layer_norm.weight', 'transformer.layer.15.output_layer_norm.bias', 'transformer.layer.3.output_layer_norm.weight', 'transformer.layer.11.ffn.lin2.weight', 'transformer.layer.22.attention.k_lin.weight', 'transformer.layer.18.ffn.lin1.bias', 'transformer.layer.28.attention.k_lin.weight', 'transformer.layer.18.ffn.lin2.bias', 'transformer.layer.18.attention.q_lin.weight', 'transformer.layer.10.ffn.lin1.weight', 'transformer.layer.29.ffn.lin2.bias', 'transformer.layer.12.sa_layer_norm.weight', 'transformer.layer.16.output_layer_norm.bias', 'transformer.layer.5.attention.out_lin.bias', 'transformer.layer.6.attention.k_lin.weight', 'transformer.layer.3.ffn.lin1.bias', 'transformer.layer.9.attention.v_lin.weight', 'transformer.layer.4.attention.k_lin.bias', 'transformer.layer.4.sa_layer_norm.weight', 'transformer.layer.11.ffn.lin2.bias', 'transformer.layer.18.sa_layer_norm.bias', 'transformer.layer.6.ffn.lin1.weight', 'transformer.layer.7.attention.q_lin.weight', 'transformer.layer.6.sa_layer_norm.weight', 'transformer.layer.17.ffn.lin2.weight', 'transformer.layer.1.attention.q_lin.weight', 'transformer.layer.22.attention.v_lin.bias', 'transformer.layer.23.sa_layer_norm.bias', 'transformer.layer.22.ffn.lin1.weight', 'transformer.layer.17.attention.q_lin.bias', 'transformer.layer.12.output_layer_norm.bias', 'transformer.layer.26.attention.q_lin.bias', 'transformer.layer.24.attention.v_lin.bias', 'transformer.layer.17.attention.v_lin.weight', 'transformer.layer.7.ffn.lin2.bias', 'transformer.layer.20.attention.k_lin.bias', 'transformer.layer.25.ffn.lin2.bias', 'transformer.layer.20.attention.q_lin.weight', 'transformer.layer.17.ffn.lin1.weight', 'transformer.layer.28.attention.v_lin.bias', 'transformer.layer.24.output_layer_norm.weight', 'transformer.layer.23.attention.v_lin.weight', 'transformer.layer.29.output_layer_norm.weight', 'transformer.layer.8.attention.v_lin.bias', 'transformer.layer.19.attention.k_lin.weight', 'transformer.layer.9.ffn.lin2.weight', 'transformer.layer.11.attention.v_lin.weight', 'transformer.layer.27.attention.out_lin.weight', 'transformer.layer.21.ffn.lin1.weight', 'transformer.layer.5.output_layer_norm.bias', 'transformer.layer.22.sa_layer_norm.weight', 'embeddings.LayerNorm.weight', 'transformer.layer.12.attention.k_lin.weight', 'transformer.layer.12.attention.q_lin.weight', 'transformer.layer.17.sa_layer_norm.weight', 'transformer.layer.18.ffn.lin1.weight', 'transformer.layer.9.ffn.lin1.bias', 'transformer.layer.4.attention.out_lin.weight', 'transformer.layer.26.ffn.lin1.bias', 'transformer.layer.29.sa_layer_norm.bias', 'transformer.layer.5.attention.q_lin.weight', 'transformer.layer.8.attention.out_lin.bias', 'transformer.layer.27.attention.q_lin.bias', 'transformer.layer.5.attention.v_lin.weight', 'transformer.layer.13.attention.q_lin.weight', 'transformer.layer.26.attention.q_lin.weight', 'transformer.layer.23.ffn.lin2.bias', 'transformer.layer.29.ffn.lin2.weight', 'transformer.layer.11.attention.q_lin.bias', 'transformer.layer.26.output_layer_norm.bias', 'transformer.layer.18.output_layer_norm.bias', 'transformer.layer.21.sa_layer_norm.weight', 'transformer.layer.7.ffn.lin2.weight', 'transformer.layer.2.ffn.lin2.weight', 'transformer.layer.25.attention.k_lin.weight', 'transformer.layer.8.ffn.lin2.bias', 'transformer.layer.26.attention.v_lin.bias', 'transformer.layer.26.attention.v_lin.weight', 'transformer.layer.14.attention.out_lin.weight', 'transformer.layer.29.attention.q_lin.bias', 'transformer.layer.24.attention.out_lin.weight', 'transformer.layer.6.output_layer_norm.bias', 'transformer.layer.23.attention.q_lin.weight', 'transformer.layer.25.ffn.lin1.bias', 'transformer.layer.23.attention.v_lin.bias', 'transformer.layer.15.attention.k_lin.weight', 'transformer.layer.18.attention.q_lin.bias', 'transformer.layer.7.attention.q_lin.bias', 'transformer.layer.16.attention.out_lin.bias', 'transformer.layer.6.attention.out_lin.bias', 'transformer.layer.29.attention.v_lin.bias', 'transformer.layer.3.attention.k_lin.bias', 'transformer.layer.20.sa_layer_norm.weight', 'transformer.layer.15.attention.v_lin.weight', 'transformer.layer.10.attention.k_lin.weight', 'transformer.layer.0.attention.out_lin.bias', 'transformer.layer.26.attention.k_lin.weight', 'transformer.layer.29.attention.v_lin.weight', 'transformer.layer.21.attention.q_lin.bias', 'transformer.layer.15.attention.q_lin.weight', 'transformer.layer.1.attention.v_lin.weight', 'transformer.layer.28.output_layer_norm.weight', 'transformer.layer.19.sa_layer_norm.bias', 'transformer.layer.22.ffn.lin2.bias', 'transformer.layer.26.attention.k_lin.bias', 'transformer.layer.21.sa_layer_norm.bias', 'transformer.layer.27.ffn.lin1.bias', 'transformer.layer.8.attention.k_lin.bias', 'transformer.layer.1.attention.q_lin.bias', 'transformer.layer.29.attention.k_lin.bias', 'transformer.layer.28.attention.out_lin.weight', 'transformer.layer.17.attention.out_lin.bias', 'transformer.layer.19.attention.out_lin.weight', 'transformer.layer.10.attention.out_lin.weight', 'transformer.layer.12.attention.out_lin.weight', 'transformer.layer.24.attention.v_lin.weight', 'transformer.layer.19.attention.q_lin.weight', 'transformer.layer.14.output_layer_norm.bias', 'transformer.layer.2.attention.out_lin.weight', 'transformer.layer.21.attention.v_lin.weight', 'transformer.layer.0.attention.q_lin.bias', 'transformer.layer.12.sa_layer_norm.bias', 'transformer.layer.24.sa_layer_norm.bias', 'transformer.layer.17.ffn.lin1.bias', 'transformer.layer.29.attention.out_lin.weight', 'transformer.layer.1.ffn.lin1.bias', 'transformer.layer.23.attention.out_lin.bias', 'transformer.layer.13.attention.out_lin.bias', 'transformer.layer.10.sa_layer_norm.bias', 'transformer.layer.16.sa_layer_norm.bias', 'transformer.layer.24.ffn.lin2.weight', 'transformer.layer.2.attention.v_lin.weight', 'transformer.layer.8.attention.q_lin.weight', 'transformer.layer.14.output_layer_norm.weight', 'transformer.layer.0.sa_layer_norm.weight', 'transformer.layer.3.ffn.lin2.bias', 'transformer.layer.29.sa_layer_norm.weight', 'transformer.layer.29.attention.out_lin.bias', 'transformer.layer.21.output_layer_norm.weight', 'transformer.layer.25.attention.k_lin.bias', 'transformer.layer.25.sa_layer_norm.weight', 'transformer.layer.3.sa_layer_norm.bias', 'transformer.layer.1.ffn.lin1.weight', 'transformer.layer.7.attention.v_lin.bias', 'transformer.layer.24.output_layer_norm.bias', 'transformer.layer.16.ffn.lin2.weight', 'transformer.layer.17.attention.v_lin.bias', 'transformer.layer.5.ffn.lin2.weight', 'transformer.layer.16.attention.out_lin.weight', 'transformer.layer.2.attention.out_lin.bias', 'transformer.layer.18.attention.v_lin.weight', 'transformer.layer.7.ffn.lin1.weight', 'transformer.layer.4.output_layer_norm.weight', 'transformer.layer.23.ffn.lin1.bias', 'transformer.layer.13.attention.v_lin.weight', 'transformer.layer.15.attention.out_lin.weight', 'transformer.layer.27.attention.k_lin.weight', 'transformer.layer.8.sa_layer_norm.bias', 'transformer.layer.13.attention.out_lin.weight', 'transformer.layer.19.ffn.lin1.bias', 'transformer.layer.22.attention.q_lin.bias', 'embeddings.word_embeddings.weight', 'transformer.layer.11.attention.out_lin.bias', 'transformer.layer.11.attention.q_lin.weight', 'transformer.layer.3.ffn.lin2.weight', 'transformer.layer.14.ffn.lin1.weight', 'transformer.layer.16.ffn.lin2.bias', 'embeddings.position_embeddings.weight', 'transformer.layer.24.attention.q_lin.weight', 'transformer.layer.8.output_layer_norm.bias', 'transformer.layer.2.attention.q_lin.bias', 'transformer.layer.11.ffn.lin1.weight', 'transformer.layer.11.attention.k_lin.bias', 'transformer.layer.28.output_layer_norm.bias', 'transformer.layer.4.ffn.lin1.bias', 'transformer.layer.22.ffn.lin2.weight', 'transformer.layer.10.attention.q_lin.bias', 'transformer.layer.25.output_layer_norm.bias', 'transformer.layer.11.sa_layer_norm.bias', 'transformer.layer.13.ffn.lin1.weight', 'transformer.layer.13.sa_layer_norm.weight', 'transformer.layer.8.attention.out_lin.weight', 'transformer.layer.0.ffn.lin1.weight', 'transformer.layer.3.attention.out_lin.weight', 'transformer.layer.3.attention.q_lin.bias', 'transformer.layer.1.sa_layer_norm.weight', 'transformer.layer.4.attention.v_lin.bias', 'transformer.layer.21.output_layer_norm.bias', 'transformer.layer.28.ffn.lin1.bias', 'transformer.layer.25.attention.v_lin.bias', 'transformer.layer.1.attention.out_lin.weight', 'transformer.layer.6.attention.k_lin.bias', 'transformer.layer.9.attention.v_lin.bias', 'transformer.layer.15.sa_layer_norm.bias', 'transformer.layer.28.attention.k_lin.bias', 'transformer.layer.4.output_layer_norm.bias', 'transformer.layer.10.ffn.lin2.weight', 'transformer.layer.23.output_layer_norm.weight', 'transformer.layer.8.attention.q_lin.bias', 'transformer.layer.0.attention.v_lin.bias', 'transformer.layer.25.ffn.lin1.weight', 'transformer.layer.12.ffn.lin1.bias', 'transformer.layer.24.ffn.lin1.weight', 'transformer.layer.25.sa_layer_norm.bias', 'transformer.layer.18.attention.out_lin.bias', 'transformer.layer.1.output_layer_norm.weight', 'transformer.layer.15.ffn.lin1.weight', 'transformer.layer.27.ffn.lin2.weight', 'transformer.layer.16.attention.v_lin.bias', 'transformer.layer.13.ffn.lin2.weight', 'transformer.layer.7.attention.out_lin.weight', 'transformer.layer.28.ffn.lin2.bias', 'transformer.layer.14.sa_layer_norm.bias', 'transformer.layer.13.sa_layer_norm.bias', 'transformer.layer.13.attention.k_lin.bias', 'transformer.layer.4.sa_layer_norm.bias', 'transformer.layer.19.ffn.lin1.weight', 'transformer.layer.17.attention.k_lin.bias', 'transformer.layer.22.output_layer_norm.bias', 'transformer.layer.12.ffn.lin1.weight', 'transformer.layer.2.output_layer_norm.weight', 'transformer.layer.3.output_layer_norm.bias', 'transformer.layer.5.sa_layer_norm.bias', 'transformer.layer.2.ffn.lin2.bias', 'transformer.layer.16.attention.q_lin.weight', 'transformer.layer.18.attention.k_lin.bias', 'transformer.layer.7.attention.v_lin.weight', 'transformer.layer.11.ffn.lin1.bias', 'transformer.layer.9.attention.k_lin.weight', 'transformer.layer.0.sa_layer_norm.bias', 'transformer.layer.26.ffn.lin2.bias', 'transformer.layer.20.ffn.lin1.weight', 'transformer.layer.19.attention.out_lin.bias', 'transformer.layer.0.attention.v_lin.weight', 'transformer.layer.9.attention.q_lin.bias', 'transformer.layer.10.attention.v_lin.weight', 'transformer.layer.11.output_layer_norm.bias', 'transformer.layer.9.ffn.lin1.weight', 'transformer.layer.17.ffn.lin2.bias', 'transformer.layer.28.ffn.lin2.weight', 'transformer.layer.9.sa_layer_norm.weight', 'transformer.layer.4.attention.v_lin.weight', 'transformer.layer.27.ffn.lin2.bias', 'transformer.layer.21.attention.k_lin.weight', 'transformer.layer.2.ffn.lin1.weight', 'transformer.layer.20.attention.out_lin.bias', 'transformer.layer.13.output_layer_norm.bias', 'transformer.layer.18.attention.k_lin.weight', 'transformer.layer.21.ffn.lin2.bias', 'transformer.layer.1.attention.k_lin.weight', 'transformer.layer.13.ffn.lin2.bias', 'transformer.layer.14.attention.out_lin.bias', 'transformer.layer.3.attention.k_lin.weight', 'transformer.layer.15.output_layer_norm.weight', 'transformer.layer.2.sa_layer_norm.weight', 'transformer.layer.0.output_layer_norm.weight', 'transformer.layer.20.ffn.lin2.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBERTClass(\n",
              "  (l1): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(40000, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-29): 30 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (k_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_lin): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=1024, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (lin1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (lin2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (lin3): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (classifier): Linear(in_features=64, out_features=500, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model.\n",
        "\n",
        "class DistilBERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistilBERTClass, self).__init__()\n",
        "        self.l1 = DistilBertModel.from_pretrained(PRE_TRAINED_MODEL)\n",
        "        self.pre_classifier = torch.nn.Linear(MAX_LEN, MAX_LEN)\n",
        "        self.dropout = torch.nn.Dropout(0.1)\n",
        "        self.lin1 = torch.nn.Linear(1024, 512)\n",
        "        self.lin2 = torch.nn.Linear(512, 256)\n",
        "        self.lin3 = torch.nn.Linear(256,64)\n",
        "        self.classifier = torch.nn.Linear(64, NUM_LABELS)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids, num_pre_classifiers=1):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = self.lin1(pooler)\n",
        "        pooler = self.lin2(pooler)\n",
        "        pooler = self.lin3(pooler)\n",
        "        pooler = torch.nn.Tanh()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        return output\n",
        "\n",
        "model = DistilBERTClass()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ_wI0YwDVJZ"
      },
      "outputs": [],
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO49FuR9DXsW"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvmZexewUhRE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def load_model_ckp(checkpoint_path, model, optimizer):\n",
        "  checkpoint = torch.load(checkpoint_path)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  return model, optimizer, checkpoint['epoch'], checkpoint['loss']\n",
        "\n",
        "def save_model_ckp(epoch, model, optimizer,loss, save_path):\n",
        "  torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, save_path)\n",
        "\n",
        "def save_model(model, model_dir, model_name='model.pth'):\n",
        "    path = os.path.join(model_dir, model_name)\n",
        "    # recommended way from http://pytorch.org/docs/master/notes/serialization.html\n",
        "    torch.save(model.state_dict(), path)\n",
        "    logger.info(f\"Saving model: {path} \\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb9-Yr9YDZqo"
      },
      "outputs": [],
      "source": [
        "CHECKPOINT_DIR = '/content/drive/MyDrive/5minit_prot/CAFA_TORCH_MODELS'\n",
        "CHECKPOINT_MODEL_PREFIX = 'distillBert_from_protbert'\n",
        "def train(epoch, model):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for _,data in tqdm(enumerate(training_loader, 0)):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        losses.append(loss.item())\n",
        "        if _%5000==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "            now = datetime.datetime.now()\n",
        "            now = now.strftime(\"%Y%m%d%H%M%S\")\n",
        "            model_name = f\"{CHECKPOINT_MODEL_PREFIX}_epoch{epoch}_{now}.pth\"\n",
        "            save_path = os.path.join(CHECKPOINT_DIR,model_name)\n",
        "            save_model_ckp(epoch, model, optimizer,loss, save_path)\n",
        "\n",
        "            writer.add_scalar('Loss/Val', np.mean(losses), _)\n",
        "            ##writer.add_scalar('Accuracy/Val', acc, _)\n",
        "            writer.add_hparams(hparam_dict = {'lr': LEARNING_RATE, 'bsize': TRAIN_BATCH_SIZE} ,\n",
        "                       metric_dict = {'Loss/Val': np.mean(losses),\n",
        "                                      ##'Accuracy/Val' : acc,\n",
        "                                      'Step':_},\n",
        "                       hparam_domain_discrete=None,\n",
        "                       run_name=None)\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Reta6H84DcJq"
      },
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    train(epoch, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yp6SQ6iDlx0p"
      },
      "outputs": [],
      "source": [
        "# pool of size=3, stride=2\n",
        "m = torch.nn.MaxPool1d(20, stride=2)\n",
        "input = torch.randn(1024, 1)\n",
        "output = m(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Bv3-E-bl5kw"
      },
      "outputs": [],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPqZKQ1BDfLW"
      },
      "outputs": [],
      "source": [
        "def validation(testing_loader, val_model):\n",
        "    val_model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "            ##fin_outputs.extend(torch.softmax(outputs,dim=1).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blZa10yR0yU4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "1db91e40-e10f-4b19-b570-3dce526bb435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_fn\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:model_fn\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the trained model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing DistilBertModel: ['bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.13.attention.self.query.weight', 'bert.encoder.layer.18.attention.output.LayerNorm.weight', 'bert.encoder.layer.12.attention.output.dense.bias', 'bert.encoder.layer.19.attention.self.value.bias', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.20.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.29.attention.self.query.weight', 'bert.encoder.layer.29.intermediate.dense.bias', 'bert.encoder.layer.25.attention.output.dense.bias', 'bert.encoder.layer.20.attention.self.query.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.12.output.dense.bias', 'bert.encoder.layer.25.intermediate.dense.weight', 'bert.encoder.layer.29.attention.self.key.bias', 'bert.encoder.layer.18.output.LayerNorm.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.15.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.16.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.27.output.dense.bias', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.29.attention.self.query.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.22.attention.self.value.bias', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.19.output.dense.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.14.attention.self.query.weight', 'bert.encoder.layer.12.attention.self.query.bias', 'bert.encoder.layer.20.intermediate.dense.bias', 'bert.encoder.layer.21.attention.output.dense.weight', 'bert.encoder.layer.29.attention.output.LayerNorm.bias', 'bert.encoder.layer.14.attention.output.dense.bias', 'bert.encoder.layer.26.output.LayerNorm.weight', 'bert.encoder.layer.20.attention.output.LayerNorm.bias', 'bert.encoder.layer.12.output.dense.weight', 'bert.encoder.layer.15.output.dense.bias', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.24.attention.output.LayerNorm.bias', 'bert.encoder.layer.21.attention.self.query.bias', 'bert.encoder.layer.24.output.LayerNorm.bias', 'bert.encoder.layer.26.attention.self.value.weight', 'bert.encoder.layer.23.attention.self.query.bias', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.24.attention.self.value.weight', 'bert.encoder.layer.19.intermediate.dense.bias', 'bert.encoder.layer.18.output.LayerNorm.bias', 'bert.encoder.layer.13.intermediate.dense.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.16.attention.self.value.weight', 'bert.encoder.layer.21.attention.output.LayerNorm.bias', 'bert.encoder.layer.19.output.LayerNorm.weight', 'bert.encoder.layer.27.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.27.attention.output.dense.bias', 'bert.encoder.layer.27.attention.output.LayerNorm.bias', 'bert.encoder.layer.24.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.26.attention.self.query.bias', 'bert.encoder.layer.26.attention.self.value.bias', 'bert.encoder.layer.19.attention.self.query.weight', 'bert.encoder.layer.25.output.dense.weight', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.24.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.21.attention.output.dense.bias', 'bert.encoder.layer.20.attention.self.key.bias', 'bert.encoder.layer.19.attention.output.LayerNorm.bias', 'bert.encoder.layer.25.output.LayerNorm.weight', 'bert.encoder.layer.13.output.LayerNorm.weight', 'bert.encoder.layer.22.output.LayerNorm.bias', 'bert.encoder.layer.25.attention.self.key.bias', 'bert.encoder.layer.29.attention.self.value.weight', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.13.output.dense.bias', 'bert.encoder.layer.14.output.LayerNorm.weight', 'bert.encoder.layer.15.output.dense.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.14.intermediate.dense.bias', 'bert.encoder.layer.27.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.22.attention.self.value.weight', 'bert.encoder.layer.25.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.25.attention.output.LayerNorm.weight', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.23.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.26.attention.output.LayerNorm.bias', 'bert.encoder.layer.16.attention.self.query.weight', 'bert.encoder.layer.14.attention.output.dense.weight', 'bert.encoder.layer.22.attention.output.dense.weight', 'bert.encoder.layer.19.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.24.output.LayerNorm.weight', 'bert.encoder.layer.29.output.dense.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.12.intermediate.dense.weight', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.17.attention.output.dense.bias', 'bert.encoder.layer.19.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.21.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.17.attention.self.value.weight', 'cls.predictions.bias', 'bert.encoder.layer.13.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.22.intermediate.dense.weight', 'bert.encoder.layer.14.attention.self.key.weight', 'bert.encoder.layer.24.attention.output.dense.weight', 'bert.encoder.layer.24.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.19.attention.self.query.bias', 'bert.encoder.layer.20.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.14.attention.self.query.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.15.intermediate.dense.bias', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.24.attention.output.LayerNorm.weight', 'bert.encoder.layer.25.output.LayerNorm.bias', 'bert.encoder.layer.14.output.LayerNorm.bias', 'bert.encoder.layer.28.intermediate.dense.weight', 'bert.encoder.layer.25.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.17.attention.output.LayerNorm.bias', 'bert.encoder.layer.23.attention.output.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.21.attention.self.query.weight', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.17.intermediate.dense.bias', 'bert.encoder.layer.17.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.20.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.21.attention.self.key.bias', 'bert.encoder.layer.28.attention.self.value.weight', 'bert.encoder.layer.13.output.dense.weight', 'bert.encoder.layer.28.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.15.attention.output.dense.weight', 'bert.encoder.layer.27.output.LayerNorm.bias', 'cls.predictions.decoder.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.18.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.29.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.21.attention.self.key.weight', 'bert.encoder.layer.20.output.LayerNorm.weight', 'bert.encoder.layer.28.output.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.17.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.27.attention.self.value.bias', 'bert.encoder.layer.29.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.12.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.28.attention.self.query.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.17.attention.output.dense.weight', 'bert.encoder.layer.20.attention.output.dense.bias', 'bert.encoder.layer.28.attention.output.LayerNorm.bias', 'bert.encoder.layer.14.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.18.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.16.output.LayerNorm.bias', 'bert.encoder.layer.24.attention.self.value.bias', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.27.output.dense.weight', 'bert.encoder.layer.29.attention.self.key.weight', 'bert.encoder.layer.27.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'cls.predictions.decoder.weight', 'bert.encoder.layer.29.output.dense.weight', 'bert.encoder.layer.21.attention.output.LayerNorm.weight', 'bert.encoder.layer.20.output.dense.bias', 'bert.encoder.layer.29.attention.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.24.output.dense.bias', 'bert.pooler.dense.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.21.output.LayerNorm.weight', 'bert.encoder.layer.23.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.27.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.21.attention.self.value.bias', 'bert.encoder.layer.18.intermediate.dense.weight', 'bert.encoder.layer.12.attention.self.query.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.19.attention.self.key.weight', 'bert.encoder.layer.23.output.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.26.attention.output.dense.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.23.attention.self.key.bias', 'bert.encoder.layer.13.attention.self.query.bias', 'bert.encoder.layer.14.output.dense.bias', 'bert.encoder.layer.24.output.dense.weight', 'bert.encoder.layer.19.output.dense.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.14.intermediate.dense.weight', 'bert.encoder.layer.18.attention.self.key.bias', 'bert.encoder.layer.16.output.dense.bias', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.19.attention.output.dense.bias', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.25.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.26.attention.output.dense.weight', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.embeddings.position_embeddings.weight', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.17.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.17.attention.self.query.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.23.attention.self.value.weight', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.16.intermediate.dense.bias', 'bert.encoder.layer.26.output.dense.bias', 'bert.encoder.layer.12.attention.output.LayerNorm.bias', 'bert.encoder.layer.13.output.LayerNorm.bias', 'bert.encoder.layer.24.intermediate.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.14.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.29.output.LayerNorm.weight', 'bert.encoder.layer.13.attention.self.value.bias', 'bert.encoder.layer.22.attention.output.dense.bias', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.22.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.28.attention.output.dense.bias', 'bert.encoder.layer.17.attention.self.query.bias', 'bert.encoder.layer.28.attention.self.value.bias', 'bert.encoder.layer.13.attention.output.LayerNorm.weight', 'bert.encoder.layer.12.attention.output.dense.weight', 'bert.encoder.layer.23.attention.output.dense.weight', 'bert.encoder.layer.16.output.LayerNorm.weight', 'bert.encoder.layer.16.attention.self.key.bias', 'bert.encoder.layer.20.intermediate.dense.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.20.attention.self.value.bias', 'bert.encoder.layer.13.attention.output.dense.weight', 'bert.encoder.layer.15.attention.self.key.weight', 'bert.encoder.layer.16.attention.self.value.bias', 'bert.encoder.layer.17.output.dense.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.27.attention.self.key.bias', 'bert.encoder.layer.20.output.dense.weight', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.26.attention.self.key.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.17.intermediate.dense.weight', 'bert.encoder.layer.18.attention.output.dense.weight', 'bert.encoder.layer.27.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.19.attention.self.key.bias', 'bert.encoder.layer.28.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.23.intermediate.dense.bias', 'cls.seq_relationship.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.18.output.dense.weight', 'bert.encoder.layer.23.output.LayerNorm.weight', 'bert.encoder.layer.19.intermediate.dense.weight', 'bert.encoder.layer.14.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.21.output.dense.bias', 'bert.encoder.layer.12.output.LayerNorm.bias', 'bert.encoder.layer.29.attention.output.dense.weight', 'bert.encoder.layer.22.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.18.attention.self.query.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.23.attention.self.key.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.15.attention.output.LayerNorm.bias', 'bert.encoder.layer.17.attention.self.value.bias', 'bert.encoder.layer.28.attention.self.key.weight', 'bert.encoder.layer.23.attention.self.value.bias', 'bert.encoder.layer.16.attention.output.LayerNorm.weight', 'bert.encoder.layer.25.intermediate.dense.bias', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.25.attention.self.value.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.16.attention.self.query.bias', 'bert.encoder.layer.12.attention.self.key.weight', 'bert.encoder.layer.12.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.27.intermediate.dense.weight', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.26.output.dense.weight', 'bert.encoder.layer.12.intermediate.dense.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.26.attention.self.key.bias', 'bert.encoder.layer.20.output.LayerNorm.bias', 'bert.encoder.layer.23.output.dense.weight', 'bert.encoder.layer.15.attention.self.query.bias', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.25.output.dense.bias', 'bert.encoder.layer.13.attention.self.key.bias', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.14.output.dense.weight', 'bert.encoder.layer.17.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.13.attention.self.key.weight', 'bert.encoder.layer.28.output.dense.bias', 'bert.encoder.layer.28.intermediate.dense.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.16.attention.output.dense.bias', 'bert.encoder.layer.16.attention.output.dense.weight', 'bert.encoder.layer.15.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.23.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.encoder.layer.18.attention.self.value.weight', 'bert.encoder.layer.25.attention.self.query.bias', 'bert.encoder.layer.18.attention.self.query.bias', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.22.attention.self.query.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.12.attention.output.LayerNorm.weight', 'bert.encoder.layer.13.attention.self.value.weight', 'bert.encoder.layer.22.attention.self.key.bias', 'bert.encoder.layer.24.attention.self.query.bias', 'bert.encoder.layer.16.attention.self.key.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.15.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.28.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.21.intermediate.dense.weight', 'bert.encoder.layer.14.attention.output.LayerNorm.weight', 'bert.encoder.layer.27.attention.self.query.bias', 'bert.encoder.layer.29.attention.self.value.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.15.attention.self.value.bias', 'bert.encoder.layer.29.intermediate.dense.weight', 'bert.encoder.layer.22.output.dense.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.20.attention.self.key.weight', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.21.intermediate.dense.bias', 'bert.encoder.layer.15.attention.self.query.weight', 'bert.encoder.layer.15.attention.output.LayerNorm.weight', 'bert.encoder.layer.26.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.23.intermediate.dense.weight', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.13.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.15.output.LayerNorm.bias', 'bert.encoder.layer.28.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.22.attention.output.LayerNorm.weight', 'bert.encoder.layer.26.attention.self.query.weight', 'bert.encoder.layer.19.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.18.output.dense.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.12.attention.self.value.bias', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.22.attention.self.key.weight', 'bert.encoder.layer.26.intermediate.dense.weight', 'bert.encoder.layer.14.attention.self.value.weight', 'bert.encoder.layer.20.attention.output.LayerNorm.weight', 'bert.encoder.layer.27.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.12.attention.self.value.weight', 'cls.seq_relationship.weight', 'bert.encoder.layer.21.output.LayerNorm.bias', 'bert.encoder.layer.18.attention.self.key.weight', 'bert.encoder.layer.26.output.LayerNorm.bias', 'bert.encoder.layer.24.attention.self.key.bias', 'bert.encoder.layer.22.output.dense.weight', 'bert.encoder.layer.25.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.27.attention.self.key.weight', 'bert.encoder.layer.17.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.17.output.dense.bias', 'bert.encoder.layer.13.attention.output.dense.bias', 'bert.encoder.layer.21.output.dense.weight', 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.15.intermediate.dense.weight', 'bert.encoder.layer.16.output.dense.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.16.intermediate.dense.weight', 'bert.encoder.layer.18.intermediate.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.28.attention.self.key.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.25.attention.output.dense.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.15.attention.self.value.weight', 'bert.encoder.layer.24.attention.self.key.weight', 'bert.encoder.layer.18.attention.self.value.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.22.attention.self.query.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.26.intermediate.dense.bias', 'bert.pooler.dense.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.28.attention.self.query.weight', 'bert.encoder.layer.19.attention.output.dense.weight', 'bert.encoder.layer.23.attention.self.query.weight', 'bert.encoder.layer.22.intermediate.dense.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertModel were not initialized from the model checkpoint at Rostlab/prot_bert and are newly initialized: ['transformer.layer.17.attention.out_lin.weight', 'transformer.layer.27.attention.v_lin.weight', 'transformer.layer.9.output_layer_norm.bias', 'transformer.layer.6.output_layer_norm.weight', 'transformer.layer.22.ffn.lin1.bias', 'transformer.layer.27.output_layer_norm.weight', 'transformer.layer.27.sa_layer_norm.bias', 'transformer.layer.4.ffn.lin2.weight', 'transformer.layer.22.attention.q_lin.weight', 'transformer.layer.0.ffn.lin2.bias', 'transformer.layer.15.ffn.lin1.bias', 'transformer.layer.4.attention.q_lin.weight', 'transformer.layer.24.attention.k_lin.weight', 'transformer.layer.19.sa_layer_norm.weight', 'transformer.layer.18.output_layer_norm.weight', 'transformer.layer.2.ffn.lin1.bias', 'transformer.layer.9.attention.out_lin.bias', 'transformer.layer.14.attention.k_lin.weight', 'transformer.layer.15.attention.q_lin.bias', 'transformer.layer.24.attention.out_lin.bias', 'transformer.layer.26.attention.out_lin.bias', 'transformer.layer.27.attention.q_lin.weight', 'transformer.layer.10.ffn.lin2.bias', 'transformer.layer.7.ffn.lin1.bias', 'transformer.layer.28.sa_layer_norm.bias', 'transformer.layer.10.attention.out_lin.bias', 'transformer.layer.6.attention.out_lin.weight', 'transformer.layer.10.output_layer_norm.weight', 'transformer.layer.15.attention.v_lin.bias', 'transformer.layer.13.attention.k_lin.weight', 'transformer.layer.6.attention.v_lin.bias', 'transformer.layer.0.attention.k_lin.bias', 'transformer.layer.25.attention.out_lin.bias', 'transformer.layer.21.attention.v_lin.bias', 'transformer.layer.29.ffn.lin1.bias', 'transformer.layer.0.attention.out_lin.weight', 'transformer.layer.7.attention.k_lin.weight', 'transformer.layer.9.attention.q_lin.weight', 'transformer.layer.23.ffn.lin2.weight', 'transformer.layer.10.attention.q_lin.weight', 'transformer.layer.12.attention.q_lin.bias', 'transformer.layer.10.output_layer_norm.bias', 'transformer.layer.22.attention.k_lin.bias', 'transformer.layer.24.ffn.lin2.bias', 'transformer.layer.4.ffn.lin1.weight', 'transformer.layer.4.attention.k_lin.weight', 'transformer.layer.4.ffn.lin2.bias', 'transformer.layer.8.ffn.lin1.bias', 'transformer.layer.9.attention.out_lin.weight', 'transformer.layer.16.ffn.lin1.bias', 'transformer.layer.12.output_layer_norm.weight', 'transformer.layer.23.attention.out_lin.weight', 'transformer.layer.6.sa_layer_norm.bias', 'transformer.layer.13.attention.v_lin.bias', 'transformer.layer.29.output_layer_norm.bias', 'transformer.layer.26.output_layer_norm.weight', 'transformer.layer.3.sa_layer_norm.weight', 'transformer.layer.7.attention.out_lin.bias', 'transformer.layer.1.attention.k_lin.bias', 'transformer.layer.25.attention.v_lin.weight', 'transformer.layer.18.ffn.lin2.weight', 'transformer.layer.6.attention.v_lin.weight', 'transformer.layer.2.attention.k_lin.weight', 'transformer.layer.26.ffn.lin1.weight', 'transformer.layer.23.attention.q_lin.bias', 'transformer.layer.28.attention.out_lin.bias', 'transformer.layer.4.attention.out_lin.bias', 'transformer.layer.19.attention.q_lin.bias', 'transformer.layer.5.output_layer_norm.weight', 'transformer.layer.3.attention.out_lin.bias', 'transformer.layer.5.ffn.lin1.weight', 'transformer.layer.12.ffn.lin2.weight', 'transformer.layer.20.ffn.lin1.bias', 'transformer.layer.8.attention.v_lin.weight', 'transformer.layer.22.sa_layer_norm.bias', 'transformer.layer.3.attention.v_lin.weight', 'transformer.layer.0.ffn.lin1.bias', 'transformer.layer.24.ffn.lin1.bias', 'transformer.layer.15.ffn.lin2.weight', 'transformer.layer.12.ffn.lin2.bias', 'transformer.layer.12.attention.v_lin.bias', 'transformer.layer.1.ffn.lin2.weight', 'transformer.layer.17.attention.k_lin.weight', 'transformer.layer.12.attention.out_lin.bias', 'transformer.layer.9.attention.k_lin.bias', 'transformer.layer.2.attention.q_lin.weight', 'transformer.layer.0.ffn.lin2.weight', 'transformer.layer.16.attention.q_lin.bias', 'transformer.layer.23.attention.k_lin.weight', 'transformer.layer.5.attention.k_lin.bias', 'transformer.layer.15.sa_layer_norm.weight', 'transformer.layer.26.sa_layer_norm.bias', 'transformer.layer.14.attention.v_lin.weight', 'transformer.layer.9.sa_layer_norm.bias', 'transformer.layer.17.output_layer_norm.weight', 'transformer.layer.19.attention.k_lin.bias', 'transformer.layer.21.ffn.lin1.bias', 'transformer.layer.1.sa_layer_norm.bias', 'transformer.layer.21.attention.out_lin.weight', 'transformer.layer.3.ffn.lin1.weight', 'transformer.layer.26.attention.out_lin.weight', 'transformer.layer.26.sa_layer_norm.weight', 'transformer.layer.27.output_layer_norm.bias', 'transformer.layer.15.attention.k_lin.bias', 'transformer.layer.2.sa_layer_norm.bias', 'transformer.layer.21.attention.k_lin.bias', 'transformer.layer.19.output_layer_norm.bias', 'transformer.layer.9.output_layer_norm.weight', 'transformer.layer.25.attention.out_lin.weight', 'transformer.layer.5.sa_layer_norm.weight', 'transformer.layer.8.attention.k_lin.weight', 'transformer.layer.20.output_layer_norm.weight', 'transformer.layer.20.ffn.lin2.bias', 'transformer.layer.25.attention.q_lin.weight', 'transformer.layer.14.attention.q_lin.bias', 'transformer.layer.22.output_layer_norm.weight', 'transformer.layer.24.attention.q_lin.bias', 'transformer.layer.20.attention.v_lin.bias', 'transformer.layer.20.sa_layer_norm.bias', 'transformer.layer.17.attention.q_lin.weight', 'transformer.layer.19.attention.v_lin.weight', 'transformer.layer.25.output_layer_norm.weight', 'transformer.layer.14.attention.q_lin.weight', 'transformer.layer.14.attention.v_lin.bias', 'transformer.layer.17.sa_layer_norm.bias', 'transformer.layer.11.attention.v_lin.bias', 'transformer.layer.8.sa_layer_norm.weight', 'transformer.layer.15.attention.out_lin.bias', 'transformer.layer.10.ffn.lin1.bias', 'transformer.layer.29.attention.q_lin.weight', 'transformer.layer.1.ffn.lin2.bias', 'transformer.layer.7.output_layer_norm.weight', 'transformer.layer.19.attention.v_lin.bias', 'transformer.layer.17.output_layer_norm.bias', 'transformer.layer.8.ffn.lin2.weight', 'transformer.layer.10.attention.k_lin.bias', 'transformer.layer.10.sa_layer_norm.weight', 'transformer.layer.6.ffn.lin2.weight', 'transformer.layer.11.attention.k_lin.weight', 'transformer.layer.16.ffn.lin1.weight', 'transformer.layer.20.attention.k_lin.weight', 'transformer.layer.11.sa_layer_norm.weight', 'transformer.layer.21.attention.out_lin.bias', 'transformer.layer.0.attention.q_lin.weight', 'transformer.layer.27.attention.out_lin.bias', 'transformer.layer.5.attention.v_lin.bias', 'transformer.layer.12.attention.v_lin.weight', 'transformer.layer.8.output_layer_norm.weight', 'transformer.layer.27.attention.v_lin.bias', 'transformer.layer.2.attention.v_lin.bias', 'transformer.layer.14.ffn.lin2.weight', 'transformer.layer.7.attention.k_lin.bias', 'transformer.layer.20.attention.v_lin.weight', 'transformer.layer.25.attention.q_lin.bias', 'transformer.layer.23.ffn.lin1.weight', 'transformer.layer.7.sa_layer_norm.bias', 'transformer.layer.4.attention.q_lin.bias', 'transformer.layer.9.ffn.lin2.bias', 'transformer.layer.22.attention.out_lin.bias', 'transformer.layer.18.attention.out_lin.weight', 'transformer.layer.5.attention.out_lin.weight', 'transformer.layer.13.ffn.lin1.bias', 'transformer.layer.11.output_layer_norm.weight', 'transformer.layer.24.sa_layer_norm.weight', 'transformer.layer.27.attention.k_lin.bias', 'transformer.layer.21.attention.q_lin.weight', 'transformer.layer.22.attention.out_lin.weight', 'transformer.layer.10.attention.v_lin.bias', 'transformer.layer.20.output_layer_norm.bias', 'transformer.layer.1.attention.out_lin.bias', 'transformer.layer.14.ffn.lin2.bias', 'transformer.layer.0.attention.k_lin.weight', 'transformer.layer.1.output_layer_norm.bias', 'transformer.layer.28.attention.q_lin.bias', 'transformer.layer.5.attention.q_lin.bias', 'embeddings.LayerNorm.bias', 'transformer.layer.13.output_layer_norm.weight', 'transformer.layer.20.attention.q_lin.bias', 'transformer.layer.6.ffn.lin1.bias', 'transformer.layer.29.attention.k_lin.weight', 'transformer.layer.18.sa_layer_norm.weight', 'transformer.layer.5.ffn.lin1.bias', 'transformer.layer.12.attention.k_lin.bias', 'transformer.layer.16.attention.k_lin.weight', 'transformer.layer.28.sa_layer_norm.weight', 'transformer.layer.7.output_layer_norm.bias', 'transformer.layer.22.attention.v_lin.weight', 'transformer.layer.19.ffn.lin2.weight', 'transformer.layer.3.attention.q_lin.weight', 'transformer.layer.0.output_layer_norm.bias', 'transformer.layer.11.attention.out_lin.weight', 'transformer.layer.5.ffn.lin2.bias', 'transformer.layer.15.ffn.lin2.bias', 'transformer.layer.28.attention.q_lin.weight', 'transformer.layer.27.ffn.lin1.weight', 'transformer.layer.7.sa_layer_norm.weight', 'transformer.layer.21.ffn.lin2.weight', 'transformer.layer.6.attention.q_lin.bias', 'transformer.layer.16.attention.v_lin.weight', 'transformer.layer.14.attention.k_lin.bias', 'transformer.layer.19.output_layer_norm.weight', 'transformer.layer.16.sa_layer_norm.weight', 'transformer.layer.5.attention.k_lin.weight', 'transformer.layer.14.sa_layer_norm.weight', 'transformer.layer.20.attention.out_lin.weight', 'transformer.layer.8.ffn.lin1.weight', 'transformer.layer.28.ffn.lin1.weight', 'transformer.layer.18.attention.v_lin.bias', 'transformer.layer.28.attention.v_lin.weight', 'transformer.layer.13.attention.q_lin.bias', 'transformer.layer.6.attention.q_lin.weight', 'transformer.layer.24.attention.k_lin.bias', 'transformer.layer.14.ffn.lin1.bias', 'transformer.layer.25.ffn.lin2.weight', 'transformer.layer.3.attention.v_lin.bias', 'transformer.layer.19.ffn.lin2.bias', 'transformer.layer.23.output_layer_norm.bias', 'transformer.layer.29.ffn.lin1.weight', 'transformer.layer.1.attention.v_lin.bias', 'transformer.layer.23.attention.k_lin.bias', 'transformer.layer.2.output_layer_norm.bias', 'transformer.layer.2.attention.k_lin.bias', 'transformer.layer.27.sa_layer_norm.weight', 'transformer.layer.6.ffn.lin2.bias', 'transformer.layer.16.attention.k_lin.bias', 'transformer.layer.23.sa_layer_norm.weight', 'transformer.layer.26.ffn.lin2.weight', 'transformer.layer.16.output_layer_norm.weight', 'transformer.layer.15.output_layer_norm.bias', 'transformer.layer.3.output_layer_norm.weight', 'transformer.layer.11.ffn.lin2.weight', 'transformer.layer.22.attention.k_lin.weight', 'transformer.layer.18.ffn.lin1.bias', 'transformer.layer.28.attention.k_lin.weight', 'transformer.layer.18.ffn.lin2.bias', 'transformer.layer.18.attention.q_lin.weight', 'transformer.layer.10.ffn.lin1.weight', 'transformer.layer.29.ffn.lin2.bias', 'transformer.layer.12.sa_layer_norm.weight', 'transformer.layer.16.output_layer_norm.bias', 'transformer.layer.5.attention.out_lin.bias', 'transformer.layer.6.attention.k_lin.weight', 'transformer.layer.3.ffn.lin1.bias', 'transformer.layer.9.attention.v_lin.weight', 'transformer.layer.4.attention.k_lin.bias', 'transformer.layer.4.sa_layer_norm.weight', 'transformer.layer.11.ffn.lin2.bias', 'transformer.layer.18.sa_layer_norm.bias', 'transformer.layer.6.ffn.lin1.weight', 'transformer.layer.7.attention.q_lin.weight', 'transformer.layer.6.sa_layer_norm.weight', 'transformer.layer.17.ffn.lin2.weight', 'transformer.layer.1.attention.q_lin.weight', 'transformer.layer.22.attention.v_lin.bias', 'transformer.layer.23.sa_layer_norm.bias', 'transformer.layer.22.ffn.lin1.weight', 'transformer.layer.17.attention.q_lin.bias', 'transformer.layer.12.output_layer_norm.bias', 'transformer.layer.26.attention.q_lin.bias', 'transformer.layer.24.attention.v_lin.bias', 'transformer.layer.17.attention.v_lin.weight', 'transformer.layer.7.ffn.lin2.bias', 'transformer.layer.20.attention.k_lin.bias', 'transformer.layer.25.ffn.lin2.bias', 'transformer.layer.20.attention.q_lin.weight', 'transformer.layer.17.ffn.lin1.weight', 'transformer.layer.28.attention.v_lin.bias', 'transformer.layer.24.output_layer_norm.weight', 'transformer.layer.23.attention.v_lin.weight', 'transformer.layer.29.output_layer_norm.weight', 'transformer.layer.8.attention.v_lin.bias', 'transformer.layer.19.attention.k_lin.weight', 'transformer.layer.9.ffn.lin2.weight', 'transformer.layer.11.attention.v_lin.weight', 'transformer.layer.27.attention.out_lin.weight', 'transformer.layer.21.ffn.lin1.weight', 'transformer.layer.5.output_layer_norm.bias', 'transformer.layer.22.sa_layer_norm.weight', 'embeddings.LayerNorm.weight', 'transformer.layer.12.attention.k_lin.weight', 'transformer.layer.12.attention.q_lin.weight', 'transformer.layer.17.sa_layer_norm.weight', 'transformer.layer.18.ffn.lin1.weight', 'transformer.layer.9.ffn.lin1.bias', 'transformer.layer.4.attention.out_lin.weight', 'transformer.layer.26.ffn.lin1.bias', 'transformer.layer.29.sa_layer_norm.bias', 'transformer.layer.5.attention.q_lin.weight', 'transformer.layer.8.attention.out_lin.bias', 'transformer.layer.27.attention.q_lin.bias', 'transformer.layer.5.attention.v_lin.weight', 'transformer.layer.13.attention.q_lin.weight', 'transformer.layer.26.attention.q_lin.weight', 'transformer.layer.23.ffn.lin2.bias', 'transformer.layer.29.ffn.lin2.weight', 'transformer.layer.11.attention.q_lin.bias', 'transformer.layer.26.output_layer_norm.bias', 'transformer.layer.18.output_layer_norm.bias', 'transformer.layer.21.sa_layer_norm.weight', 'transformer.layer.7.ffn.lin2.weight', 'transformer.layer.2.ffn.lin2.weight', 'transformer.layer.25.attention.k_lin.weight', 'transformer.layer.8.ffn.lin2.bias', 'transformer.layer.26.attention.v_lin.bias', 'transformer.layer.26.attention.v_lin.weight', 'transformer.layer.14.attention.out_lin.weight', 'transformer.layer.29.attention.q_lin.bias', 'transformer.layer.24.attention.out_lin.weight', 'transformer.layer.6.output_layer_norm.bias', 'transformer.layer.23.attention.q_lin.weight', 'transformer.layer.25.ffn.lin1.bias', 'transformer.layer.23.attention.v_lin.bias', 'transformer.layer.15.attention.k_lin.weight', 'transformer.layer.18.attention.q_lin.bias', 'transformer.layer.7.attention.q_lin.bias', 'transformer.layer.16.attention.out_lin.bias', 'transformer.layer.6.attention.out_lin.bias', 'transformer.layer.29.attention.v_lin.bias', 'transformer.layer.3.attention.k_lin.bias', 'transformer.layer.20.sa_layer_norm.weight', 'transformer.layer.15.attention.v_lin.weight', 'transformer.layer.10.attention.k_lin.weight', 'transformer.layer.0.attention.out_lin.bias', 'transformer.layer.26.attention.k_lin.weight', 'transformer.layer.29.attention.v_lin.weight', 'transformer.layer.21.attention.q_lin.bias', 'transformer.layer.15.attention.q_lin.weight', 'transformer.layer.1.attention.v_lin.weight', 'transformer.layer.28.output_layer_norm.weight', 'transformer.layer.19.sa_layer_norm.bias', 'transformer.layer.22.ffn.lin2.bias', 'transformer.layer.26.attention.k_lin.bias', 'transformer.layer.21.sa_layer_norm.bias', 'transformer.layer.27.ffn.lin1.bias', 'transformer.layer.8.attention.k_lin.bias', 'transformer.layer.1.attention.q_lin.bias', 'transformer.layer.29.attention.k_lin.bias', 'transformer.layer.28.attention.out_lin.weight', 'transformer.layer.17.attention.out_lin.bias', 'transformer.layer.19.attention.out_lin.weight', 'transformer.layer.10.attention.out_lin.weight', 'transformer.layer.12.attention.out_lin.weight', 'transformer.layer.24.attention.v_lin.weight', 'transformer.layer.19.attention.q_lin.weight', 'transformer.layer.14.output_layer_norm.bias', 'transformer.layer.2.attention.out_lin.weight', 'transformer.layer.21.attention.v_lin.weight', 'transformer.layer.0.attention.q_lin.bias', 'transformer.layer.12.sa_layer_norm.bias', 'transformer.layer.24.sa_layer_norm.bias', 'transformer.layer.17.ffn.lin1.bias', 'transformer.layer.29.attention.out_lin.weight', 'transformer.layer.1.ffn.lin1.bias', 'transformer.layer.23.attention.out_lin.bias', 'transformer.layer.13.attention.out_lin.bias', 'transformer.layer.10.sa_layer_norm.bias', 'transformer.layer.16.sa_layer_norm.bias', 'transformer.layer.24.ffn.lin2.weight', 'transformer.layer.2.attention.v_lin.weight', 'transformer.layer.8.attention.q_lin.weight', 'transformer.layer.14.output_layer_norm.weight', 'transformer.layer.0.sa_layer_norm.weight', 'transformer.layer.3.ffn.lin2.bias', 'transformer.layer.29.sa_layer_norm.weight', 'transformer.layer.29.attention.out_lin.bias', 'transformer.layer.21.output_layer_norm.weight', 'transformer.layer.25.attention.k_lin.bias', 'transformer.layer.25.sa_layer_norm.weight', 'transformer.layer.3.sa_layer_norm.bias', 'transformer.layer.1.ffn.lin1.weight', 'transformer.layer.7.attention.v_lin.bias', 'transformer.layer.24.output_layer_norm.bias', 'transformer.layer.16.ffn.lin2.weight', 'transformer.layer.17.attention.v_lin.bias', 'transformer.layer.5.ffn.lin2.weight', 'transformer.layer.16.attention.out_lin.weight', 'transformer.layer.2.attention.out_lin.bias', 'transformer.layer.18.attention.v_lin.weight', 'transformer.layer.7.ffn.lin1.weight', 'transformer.layer.4.output_layer_norm.weight', 'transformer.layer.23.ffn.lin1.bias', 'transformer.layer.13.attention.v_lin.weight', 'transformer.layer.15.attention.out_lin.weight', 'transformer.layer.27.attention.k_lin.weight', 'transformer.layer.8.sa_layer_norm.bias', 'transformer.layer.13.attention.out_lin.weight', 'transformer.layer.19.ffn.lin1.bias', 'transformer.layer.22.attention.q_lin.bias', 'embeddings.word_embeddings.weight', 'transformer.layer.11.attention.out_lin.bias', 'transformer.layer.11.attention.q_lin.weight', 'transformer.layer.3.ffn.lin2.weight', 'transformer.layer.14.ffn.lin1.weight', 'transformer.layer.16.ffn.lin2.bias', 'embeddings.position_embeddings.weight', 'transformer.layer.24.attention.q_lin.weight', 'transformer.layer.8.output_layer_norm.bias', 'transformer.layer.2.attention.q_lin.bias', 'transformer.layer.11.ffn.lin1.weight', 'transformer.layer.11.attention.k_lin.bias', 'transformer.layer.28.output_layer_norm.bias', 'transformer.layer.4.ffn.lin1.bias', 'transformer.layer.22.ffn.lin2.weight', 'transformer.layer.10.attention.q_lin.bias', 'transformer.layer.25.output_layer_norm.bias', 'transformer.layer.11.sa_layer_norm.bias', 'transformer.layer.13.ffn.lin1.weight', 'transformer.layer.13.sa_layer_norm.weight', 'transformer.layer.8.attention.out_lin.weight', 'transformer.layer.0.ffn.lin1.weight', 'transformer.layer.3.attention.out_lin.weight', 'transformer.layer.3.attention.q_lin.bias', 'transformer.layer.1.sa_layer_norm.weight', 'transformer.layer.4.attention.v_lin.bias', 'transformer.layer.21.output_layer_norm.bias', 'transformer.layer.28.ffn.lin1.bias', 'transformer.layer.25.attention.v_lin.bias', 'transformer.layer.1.attention.out_lin.weight', 'transformer.layer.6.attention.k_lin.bias', 'transformer.layer.9.attention.v_lin.bias', 'transformer.layer.15.sa_layer_norm.bias', 'transformer.layer.28.attention.k_lin.bias', 'transformer.layer.4.output_layer_norm.bias', 'transformer.layer.10.ffn.lin2.weight', 'transformer.layer.23.output_layer_norm.weight', 'transformer.layer.8.attention.q_lin.bias', 'transformer.layer.0.attention.v_lin.bias', 'transformer.layer.25.ffn.lin1.weight', 'transformer.layer.12.ffn.lin1.bias', 'transformer.layer.24.ffn.lin1.weight', 'transformer.layer.25.sa_layer_norm.bias', 'transformer.layer.18.attention.out_lin.bias', 'transformer.layer.1.output_layer_norm.weight', 'transformer.layer.15.ffn.lin1.weight', 'transformer.layer.27.ffn.lin2.weight', 'transformer.layer.16.attention.v_lin.bias', 'transformer.layer.13.ffn.lin2.weight', 'transformer.layer.7.attention.out_lin.weight', 'transformer.layer.28.ffn.lin2.bias', 'transformer.layer.14.sa_layer_norm.bias', 'transformer.layer.13.sa_layer_norm.bias', 'transformer.layer.13.attention.k_lin.bias', 'transformer.layer.4.sa_layer_norm.bias', 'transformer.layer.19.ffn.lin1.weight', 'transformer.layer.17.attention.k_lin.bias', 'transformer.layer.22.output_layer_norm.bias', 'transformer.layer.12.ffn.lin1.weight', 'transformer.layer.2.output_layer_norm.weight', 'transformer.layer.3.output_layer_norm.bias', 'transformer.layer.5.sa_layer_norm.bias', 'transformer.layer.2.ffn.lin2.bias', 'transformer.layer.16.attention.q_lin.weight', 'transformer.layer.18.attention.k_lin.bias', 'transformer.layer.7.attention.v_lin.weight', 'transformer.layer.11.ffn.lin1.bias', 'transformer.layer.9.attention.k_lin.weight', 'transformer.layer.0.sa_layer_norm.bias', 'transformer.layer.26.ffn.lin2.bias', 'transformer.layer.20.ffn.lin1.weight', 'transformer.layer.19.attention.out_lin.bias', 'transformer.layer.0.attention.v_lin.weight', 'transformer.layer.9.attention.q_lin.bias', 'transformer.layer.10.attention.v_lin.weight', 'transformer.layer.11.output_layer_norm.bias', 'transformer.layer.9.ffn.lin1.weight', 'transformer.layer.17.ffn.lin2.bias', 'transformer.layer.28.ffn.lin2.weight', 'transformer.layer.9.sa_layer_norm.weight', 'transformer.layer.4.attention.v_lin.weight', 'transformer.layer.27.ffn.lin2.bias', 'transformer.layer.21.attention.k_lin.weight', 'transformer.layer.2.ffn.lin1.weight', 'transformer.layer.20.attention.out_lin.bias', 'transformer.layer.13.output_layer_norm.bias', 'transformer.layer.18.attention.k_lin.weight', 'transformer.layer.21.ffn.lin2.bias', 'transformer.layer.1.attention.k_lin.weight', 'transformer.layer.13.ffn.lin2.bias', 'transformer.layer.14.attention.out_lin.bias', 'transformer.layer.3.attention.k_lin.weight', 'transformer.layer.15.output_layer_norm.weight', 'transformer.layer.2.sa_layer_norm.weight', 'transformer.layer.0.output_layer_norm.weight', 'transformer.layer.20.ffn.lin2.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7f99ca166a02>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                    optimizer=new_optimizer)\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m new_model = model_fn(model_dir=MODEL_DIR,\n\u001b[0m\u001b[1;32m     16\u001b[0m                   \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'distillBert_from_protbert_epoch0_20230608222539.pth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                   \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-7f99ca166a02>\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(model_dir, model_name, num_classes)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDistilBERTClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# pass number of classes, in our case its 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnew_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     model, optimizer, epoch, loss = load_model_ckp(checkpoint_path=os.path.join(model_dir, model_name ),\n\u001b[0m\u001b[1;32m     12\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                    optimizer=new_optimizer)\n",
            "\u001b[0;32m<ipython-input-16-96a299776a9e>\u001b[0m in \u001b[0;36mload_model_ckp\u001b[0;34m(checkpoint_path, model, optimizer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model_ckp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'data/{key}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_untyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m         \u001b[0;31m# TODO: Once we decide to break serialization FC, we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "MODEL_DIR = '/content/drive/MyDrive/prot/CAFA_TORCH_MODELS'\n",
        "\n",
        "def model_fn(model_dir,\n",
        "             model_name,\n",
        "             num_classes=500):\n",
        "    logger.info('model_fn')\n",
        "    print('Loading the trained model...')\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = DistilBERTClass() # pass number of classes, in our case its 10\n",
        "    new_optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n",
        "    model, optimizer, epoch, loss = load_model_ckp(checkpoint_path=os.path.join(model_dir, model_name ),\n",
        "                    model=model,\n",
        "                   optimizer=new_optimizer)\n",
        "    return model.to(device)\n",
        "new_model = model_fn(model_dir=MODEL_DIR,\n",
        "                  model_name='distillBert_from_protbert_epoch0_20230608222539.pth',\n",
        "                  num_classes=500\n",
        "                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDdjmHR13_Nc"
      },
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    train(epoch, new_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yzLQmsdNItM"
      },
      "outputs": [],
      "source": [
        "# Saving the files for inference\n",
        "now = datetime.datetime.now()\n",
        "now = now.strftime(\"%Y%m%d%H%M%S\")\n",
        "output_dir = f'/content/drive/MyDrive/prot/{now}_CAFA_TORCH_MODELS'\n",
        "pathExists = os.path.exists(output_dir)\n",
        "if not pathExists:\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "WEIGHTS_NAME = f'{now}_distillBert_protBert.pth'\n",
        "CONFIG_NAME= f'{now}_distillBert_protBert.bin'\n",
        "\n",
        "model_to_save = new_model.module if hasattr(new_model, 'module') else new_model\n",
        "# If we save using the predefined names, we can load using `from_pretrained`\n",
        "output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
        "output_config_file = os.path.join(output_dir, CONFIG_NAME)\n",
        "\n",
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "##model_to_save.config.to_json_file(output_config_file)\n",
        "tokenizer.save_vocabulary(output_dir)\n",
        "\n",
        "print('Saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17mVNO8dagh4"
      },
      "outputs": [],
      "source": [
        "##save_model_ckp(epoch = 0, model = new_model, optimizer = ,loss, save_path):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQmJd7RvB4A-"
      },
      "outputs": [],
      "source": [
        "val_model_path = 'distillBert_from_protbert_epoch0_20230609164638.pth'\n",
        "\n",
        "val_model = model_fn(model_dir=MODEL_DIR,\n",
        "                  model_name=val_model_path,\n",
        "                  num_classes=500\n",
        "                   )\n",
        "outputs, targets = validation(testing_loader, val_model =val_model )\n",
        "\n",
        "final_outputs = np.array(outputs) >=0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9k50farZhQo"
      },
      "outputs": [],
      "source": [
        "final_outputs = np.array(outputs) >=0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qekc58XPDhIp"
      },
      "outputs": [],
      "source": [
        "val_hamming_loss = metrics.hamming_loss(targets, final_outputs)\n",
        "val_hamming_score = hamming_score(np.array(targets), np.array(final_outputs))\n",
        "\n",
        "print(f\"Hamming Score = {val_hamming_score}\")\n",
        "print(f\"Hamming Loss = {val_hamming_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUPPOn-JbFEu"
      },
      "outputs": [],
      "source": [
        "\n",
        "outputs, targets = validation(testing_loader, model =new_model )\n",
        "\n",
        "final_outputs = np.array(outputs) >=0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12ZPxu-Lik1P"
      },
      "outputs": [],
      "source": [
        "final_outputs = np.array(outputs) >=0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JijQyOKubON2"
      },
      "outputs": [],
      "source": [
        "val_hamming_loss = metrics.hamming_loss(targets, final_outputs)\n",
        "val_hamming_score = hamming_score(np.array(targets), np.array(final_outputs))\n",
        "val_f1_score      = metrics.f1_score(np.array(targets), np.array(final_outputs))\n",
        "print(f\"Hamming Score = {val_hamming_score}\")\n",
        "print(f\"Hamming Loss = {val_hamming_loss}\")\n",
        "print(f\"f1 Score = {val_f1_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quBnrPHXldI9"
      },
      "outputs": [],
      "source": [
        "submission_targets = pd.read_csv('/content/drive/MyDrive/prot/CAFA_SEQ_DATA/targets.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STqYujCflmcv"
      },
      "outputs": [],
      "source": [
        "submission_targets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bl9WzKhLsDx2"
      },
      "outputs": [],
      "source": [
        "inf_model = model_fn(model_dir=MODEL_DIR,\n",
        "                  model_name='/content/drive/MyDrive/prot/CAFA_TORCH_MODELS/distillBert_from_protbert_epoch0_20230609164638.pth',\n",
        "                  num_classes=500\n",
        "                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dycpoizgmgv-"
      },
      "outputs": [],
      "source": [
        "\n",
        "submission_targets.drop(['id', 'sequence_length', 'taxonomyID'], inplace=True, axis=1)\n",
        "submission_targets.rename(columns = {\"sequence\": \"text\"}, inplace=True)\n",
        "submission_targets.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnRoabR7n0Nz"
      },
      "outputs": [],
      "source": [
        "targ_set = InferenceDataset(submission_targets, tokenizer, MAX_LEN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITtDK2qYnmhQ"
      },
      "outputs": [],
      "source": [
        "targ_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "targ_loader = DataLoader(targ_set, **targ_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIkZJo5rovjI"
      },
      "outputs": [],
      "source": [
        "def doInference(targ_loader, targ_model):\n",
        "    targ_model.eval()\n",
        "\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in tqdm(enumerate(targ_loader, 0)):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "            fin_outputs.extend(torch.softmax(outputs,dim=1).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpjPuNEtpi1m"
      },
      "outputs": [],
      "source": [
        "inference_out = doInference(targ_loader = targ_loader, targ_model=inf_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQhQ8YlTw-d5"
      },
      "outputs": [],
      "source": [
        "inference_out= np.array(inference_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moaCpk5XxOfI"
      },
      "outputs": [],
      "source": [
        "inference_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mG7M7n5VTuDw"
      },
      "outputs": [],
      "source": [
        "class_map = np.load('/content/drive/MyDrive/prot/CAFA_SEQ_DATA/class_map.npy', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2be7SIlrVtye"
      },
      "outputs": [],
      "source": [
        "class_map = class_map.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GITgHM0Oxaiu"
      },
      "outputs": [],
      "source": [
        "submission_df = pd.DataFrame(inference_out, columns = class_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIVzrBrVTBB6"
      },
      "outputs": [],
      "source": [
        "submission_df[\"id\"]= submission_targets[\"id\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV_1BRNFTX_e"
      },
      "outputs": [],
      "source": [
        "submission_df.set_index(\"id\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-iIAtF0WzYu"
      },
      "outputs": [],
      "source": [
        "submission_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJ8bvei0W_w2"
      },
      "outputs": [],
      "source": [
        "df_melted = submission_df.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4egX_HKXsby"
      },
      "outputs": [],
      "source": [
        "df_melted.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCpgSwNhXyGF"
      },
      "outputs": [],
      "source": [
        "df_melted = df_melted.melt([\"id\"])\n",
        "df_melted.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAvYbyCRYDlw"
      },
      "outputs": [],
      "source": [
        "df_melted['variable'] = df_melted['variable'].str.replace(\"_GO\",\"GO\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXPZMr3hZoED"
      },
      "outputs": [],
      "source": [
        "df_melted.to_csv('/content/drive/MyDrive/prot/CAFA_SUBMISSION/submission_2.tsv', header=False, index=False, sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hb3cIMAimk1H"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3494243b3a034b139eb6f5bd648368bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5e2eaa539bc483f9717daaee1db88c6",
              "IPY_MODEL_1161b5d9b17448ffa9aff9164ae69943",
              "IPY_MODEL_140bcb2a5b77454dbf0bf2fecb770c2e"
            ],
            "layout": "IPY_MODEL_af8b40f775694feebd1cf6b4412fa8b0"
          }
        },
        "f5e2eaa539bc483f9717daaee1db88c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3eea9b5553d4280a7b6245a2c18d016",
            "placeholder": "​",
            "style": "IPY_MODEL_16bb2a21de024534a727bb2b84516d9a",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "1161b5d9b17448ffa9aff9164ae69943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1afa3f7834594474920c9a59f3ccba37",
            "max": 361,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3615ea8e2304a3ab684d1ba4346e1f5",
            "value": 361
          }
        },
        "140bcb2a5b77454dbf0bf2fecb770c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_146b314d591246d38358e1d9b64336b7",
            "placeholder": "​",
            "style": "IPY_MODEL_0366f9f18b3c44e982a0f942fbc73e32",
            "value": " 361/361 [00:00&lt;00:00, 33.2kB/s]"
          }
        },
        "af8b40f775694feebd1cf6b4412fa8b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3eea9b5553d4280a7b6245a2c18d016": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16bb2a21de024534a727bb2b84516d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1afa3f7834594474920c9a59f3ccba37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3615ea8e2304a3ab684d1ba4346e1f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "146b314d591246d38358e1d9b64336b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0366f9f18b3c44e982a0f942fbc73e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f218ce8509cd47f9b6ee8327df924192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea04a52557d74567ae0650e332f44e8c",
              "IPY_MODEL_5a429c5adb30450ea022595c4e46e2ca",
              "IPY_MODEL_d0465cd2627646f19c3e8f4fb18d8743"
            ],
            "layout": "IPY_MODEL_c2b52c68d11e40f1a73e89757e669db5"
          }
        },
        "ea04a52557d74567ae0650e332f44e8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_144c17728f74475083aca93270804193",
            "placeholder": "​",
            "style": "IPY_MODEL_d4a654d274fb4766b53595d07acd6a14",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "5a429c5adb30450ea022595c4e46e2ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ca6e8a40d8840859e71a17f623f7000",
            "max": 1684058277,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_322a8704cfc9461bbfb3c386391bd44d",
            "value": 1684058277
          }
        },
        "d0465cd2627646f19c3e8f4fb18d8743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeb2c08a85924c63917ef21bd6fb07bb",
            "placeholder": "​",
            "style": "IPY_MODEL_93a7309b12b54eefacf5cf36e33daaec",
            "value": " 1.68G/1.68G [00:02&lt;00:00, 624MB/s]"
          }
        },
        "c2b52c68d11e40f1a73e89757e669db5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "144c17728f74475083aca93270804193": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4a654d274fb4766b53595d07acd6a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ca6e8a40d8840859e71a17f623f7000": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "322a8704cfc9461bbfb3c386391bd44d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eeb2c08a85924c63917ef21bd6fb07bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93a7309b12b54eefacf5cf36e33daaec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}